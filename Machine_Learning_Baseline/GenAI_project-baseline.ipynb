{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b52617-8d42-46ea-97f4-19f663856faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3342cf6-773b-4650-af81-0772cdbe75a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClinVar directory: ./clinvar_data\n",
      "ClinVar VCF path: ./clinvar_data/clinvar_GRCh38_latest.vcf.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from cyvcf2 import VCF\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Base directory for ClinVar data\n",
    "BASE_DIR = \"./clinvar_data\"\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "# Filepaths\n",
    "CLINVAR_VCF_PATH = f\"{BASE_DIR}/clinvar_GRCh38_latest.vcf.gz\"\n",
    "CLINVAR_TBI_PATH = f\"{CLINVAR_VCF_PATH}.tbi\"\n",
    "\n",
    "os.environ[\"CLINVAR_DIR\"] = BASE_DIR\n",
    "os.environ[\"CLINVAR_VCF\"] = CLINVAR_VCF_PATH\n",
    "\n",
    "print(\"ClinVar directory:\", BASE_DIR)\n",
    "print(\"ClinVar VCF path:\", CLINVAR_VCF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff240b86-7eaa-476d-bca5-7d7e85ae8ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  172M  100  172M    0     0  99.0M      0  0:00:01  0:00:01 --:--:-- 99.0M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  590k  100  590k    0     0  7386k      0 --:--:-- --:--:-- --:--:-- 7386k\n",
      "Downloaded ClinVar VCF and index using curl.\n"
     ]
    }
   ],
   "source": [
    "# Download ClinVar VCF (GRCh38) with curl\n",
    "!curl -L \\\n",
    "  https://ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh38/clinvar.vcf.gz \\\n",
    "  -o $CLINVAR_VCF_PATH\n",
    "\n",
    "# Download index (.tbi)\n",
    "!curl -L \\\n",
    "  https://ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh38/clinvar.vcf.gz.tbi \\\n",
    "  -o $CLINVAR_TBI_PATH\n",
    "\n",
    "print(\"Downloaded ClinVar VCF and index using curl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c70a244-ecab-43a7-abf8-b9ea9c896aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_clinvar_strict(vcf_path: str, sample_uncertain_k: int = 100_000):\n",
    "    \"\"\"\n",
    "    STRICT ClinVar parser:\n",
    "      • SNVs only\n",
    "      • Accept *only* pure Pathogenic or pure Benign\n",
    "      • Exclude: Likely Pathogenic/Benign, Uncertain, Conflicting, mixed\n",
    "    \"\"\"\n",
    "    vcf = VCF(vcf_path)\n",
    "    benign, pathogenic, uncertain = [], [], []\n",
    "\n",
    "    def normalize_sig(val: str) -> list[str]:\n",
    "        toks = re.split(r\"[\\|;,/]+\", val)\n",
    "        out = []\n",
    "        for t in toks:\n",
    "            t = t.strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "            if t:\n",
    "                out.append(t)\n",
    "        return out\n",
    "\n",
    "    for var in tqdm(vcf, desc=\"Parsing ClinVar VCF (strict)\"):\n",
    "        # SNVs only\n",
    "        if len(var.REF) != 1 or var.ALT is None or len(var.ALT) != 1 or any(len(a) != 1 for a in var.ALT):\n",
    "            continue\n",
    "\n",
    "        clnsig = var.INFO.get(\"CLNSIG\")\n",
    "        if clnsig is None:\n",
    "            continue\n",
    "\n",
    "        toks = set(normalize_sig(str(clnsig)))\n",
    "\n",
    "        # Clinical significance flags\n",
    "        has_path = \"pathogenic\" in toks\n",
    "        has_ben  = \"benign\" in toks\n",
    "        has_lpath = \"likely_pathogenic\" in toks\n",
    "        has_lben  = \"likely_benign\" in toks\n",
    "        has_unc   = \"uncertain_significance\" in toks\n",
    "        has_conf  = \"conflicting_interpretations_of_pathogenicity\" in toks\n",
    "\n",
    "        # STRICT filtering: drop uncertain, conflicting, likely*\n",
    "        if has_conf or has_unc or has_lpath or has_lben:\n",
    "            continue\n",
    "\n",
    "        # Drop mixed pathogenic+benign\n",
    "        if has_path and has_ben:\n",
    "            continue\n",
    "\n",
    "        # Accept pure classes only\n",
    "        if has_path and not has_ben:\n",
    "            pathogenic.append(var)\n",
    "            continue\n",
    "        if has_ben and not has_path:\n",
    "            benign.append(var)\n",
    "            continue\n",
    "\n",
    "        # All other mixed/unhandled cases are dropped\n",
    "\n",
    "    print(f\"STRICT collection complete → benign={len(benign)}, pathogenic={len(pathogenic)}\")\n",
    "    return benign, pathogenic, uncertain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e75ad612-1371-4306-9fe2-4d6afe934461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing ClinVar VCF (strict): 4125815it [00:50, 80944.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRICT collection complete → benign=180304, pathogenic=82205\n",
      "Final strict dataset size: 262509\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHROM</th>\n",
       "      <th>POS</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "      <th>CLNSIG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>930165</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>930204</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>930285</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>930314</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>930325</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CHROM     POS REF ALT  CLNSIG\n",
       "0     1  930165   G   A  Benign\n",
       "1     1  930204   G   A  Benign\n",
       "2     1  930285   G   A  Benign\n",
       "3     1  930314   C   T  Benign\n",
       "4     1  930325   C   T  Benign"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run parser and convert results into a DataFrame\n",
    "benign_vars, pathogenic_vars, _ = parse_clinvar_strict(CLINVAR_VCF_PATH)\n",
    "\n",
    "def to_dataframe(vars_list, label):\n",
    "    rows = []\n",
    "    for v in vars_list:\n",
    "        rows.append({\n",
    "            \"CHROM\": v.CHROM,\n",
    "            \"POS\": v.POS,\n",
    "            \"REF\": v.REF,\n",
    "            \"ALT\": v.ALT[0],\n",
    "            \"CLNSIG\": label\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_benign = to_dataframe(benign_vars, \"Benign\")\n",
    "df_pathogenic = to_dataframe(pathogenic_vars, \"Pathogenic\")\n",
    "\n",
    "df = pd.concat([df_benign, df_pathogenic], ignore_index=True)\n",
    "\n",
    "print(\"Final strict dataset size:\", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27e9a3d0-cf3c-48ed-97a8-5362cabdfaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved strict dataset to: ./clinvar_data/clinvar_snv_pathogenic_benign_STRICT.csv\n"
     ]
    }
   ],
   "source": [
    "# Save dataset \n",
    "output_csv = f\"{BASE_DIR}/clinvar_snv_pathogenic_benign_STRICT.csv\"\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(\"Saved strict dataset to:\", output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0176e8d1-c4ab-48f0-abb0-d0fc792d56cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5f0438b-c2e8-4a7f-9f10-f5088ad88683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CADD will be stored in: ./cadd_data\n"
     ]
    }
   ],
   "source": [
    "# Annotation-based Features\n",
    "\n",
    "# Feature 1: CADD\n",
    "# Could use this as a baseline only. Evaluate this versus adding additional annotation/sequence based features to a model\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pysam\n",
    "\n",
    "CADD_DIR = \"./cadd_data\"\n",
    "os.makedirs(CADD_DIR, exist_ok=True)\n",
    "\n",
    "CADD_TSV = f\"{CADD_DIR}/gnomad_snv_cadd.tsv.gz\"\n",
    "CADD_TBI = f\"{CADD_TSV}.tbi\"\n",
    "\n",
    "print(\"CADD will be stored in:\", CADD_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e32cc7a-9eea-49de-8c7d-c8c66f37fffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's skip the whole genome (300GB uncompressed) for now\n",
    "#import os\n",
    "\n",
    "#CADD_DIR = \"./cadd_data\"\n",
    "#os.makedirs(CADD_DIR, exist_ok=True)\n",
    "\n",
    "#CADD_TSV = f\"{CADD_DIR}/CADD_GRCh38_v1.6.tsv.gz\"\n",
    "#CADD_TBI = f\"{CADD_TSV}.tbi\"\n",
    "\n",
    "# Download CADD SNV scores for GRCh38\n",
    "#!curl -L \\\n",
    "#  https://krishna.gs.washington.edu/download/CADD/v1.6/GRCh38/whole_genome_SNVs.tsv.gz \\\n",
    "#  -o $CADD_TSV\n",
    "\n",
    "#!curl -L \\\n",
    "#  https://krishna.gs.washington.edu/download/CADD/v1.6/GRCh38/whole_genome_SNVs.tsv.gz.tbi \\\n",
    "#  -o $CADD_TBI\n",
    "\n",
    "#print(\"Downloaded CADD v1.6 GRCh38 SNV scores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1b84a4-d662-41be-b3d2-bc0de73214d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 6058M  100 6058M    0     0  38.0M      0  0:02:39  0:02:39 --:--:-- 41.3M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2503k  100 2503k    0     0  3419k      0 --:--:-- --:--:-- --:--:-- 3414k\n",
      "Downloaded gnomAD-based CADD SNV file (v1.6, GRCh38).\n"
     ]
    }
   ],
   "source": [
    "# gnomAD-based CADD SNV file (≈6GB)\n",
    "# May miss some rare variants. Could use this versus whole genome as a comparison for final project\n",
    "!curl -L \\\n",
    "  https://krishna.gs.washington.edu/download/CADD/v1.6/GRCh38/gnomad.genomes.r3.0.snv.tsv.gz \\\n",
    "  -o $CADD_TSV\n",
    "\n",
    "!curl -L \\\n",
    "  https://krishna.gs.washington.edu/download/CADD/v1.6/GRCh38/gnomad.genomes.r3.0.snv.tsv.gz.tbi \\\n",
    "  -o $CADD_TBI\n",
    "\n",
    "print(\"Downloaded gnomAD-based CADD SNV file (v1.6, GRCh38).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f8c9bfc-d7ea-4061-9c1e-6de924865fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ClinVar SNV dataset: (262509, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3995140/198660698.py:2: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"./clinvar_data/clinvar_snv_pathogenic_benign_STRICT.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Load ClinVar\n",
    "df = pd.read_csv(\"./clinvar_data/clinvar_snv_pathogenic_benign_STRICT.csv\")\n",
    "print(\"Loaded ClinVar SNV dataset:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "214a4a57-4142-446a-b3c5-49b9f8a60f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CADD Lookup Function\n",
    "\n",
    "# CADD TSV format:\n",
    "# Chrom  Pos  Ref  Alt  RawScore  PHRED\n",
    "\n",
    "# Use tabix to fetch rows efficiently\n",
    "cadd_tabix = pysam.TabixFile(CADD_TSV)\n",
    "\n",
    "def get_cadd_score(chrom, pos, ref, alt, tabix_obj):\n",
    "    \"\"\"\n",
    "    Fetch CADD raw + PHRED scores for a single SNV.\n",
    "    Works with gnomAD CADD SNV TSV files.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # CADD uses 1-based chromosome indexing\n",
    "        region = tabix_obj.fetch(chrom, pos-1, pos)\n",
    "    except ValueError:\n",
    "        return None, None\n",
    "\n",
    "    for row in region:\n",
    "        fields = row.split(\"\\t\")\n",
    "        c_ref = fields[2]\n",
    "        c_alt = fields[3]\n",
    "        if c_ref == ref and c_alt == alt:\n",
    "            raw = float(fields[4])\n",
    "            phred = float(fields[5])\n",
    "            return raw, phred\n",
    "\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d270b561-6b87-4738-b385-c8a2fb7b7263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c2e1ad-9fc4-4b80-a607-f81ae6595383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ref_genome.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbbdee5-73a8-46d1-aa46-9eff15011825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vcf.seqnames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb2c161-672d-42c2-b32a-f17a69314678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Map RefSeq NC_* accessions to Ensembl-like chrom labels when possible\n",
    "NC_TO_ENSEMBL_SPECIAL = {\n",
    "    23: \"X\",\n",
    "    24: \"Y\",\n",
    "    12920: \"MT\",  # NC_012920.1 → mitochondrion\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c49da2-4842-4439-a9ca-85dbc016c78a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def contig_candidates(chrom: str) -> List[str]:\n",
    "    \"\"\"Return plausible contig name candidates across naming conventions.\n",
    "    - Accepts inputs like 'chr1', '1', 'NC_000001.11', 'chrX', 'X', 'MT', 'chrM'\n",
    "    - Returns unique candidates in priority order.\n",
    "    \"\"\"\n",
    "    cands = []\n",
    "    # As-is\n",
    "    cands.append(chrom)\n",
    "\n",
    "    # Strip/add 'chr'\n",
    "    if chrom.startswith(\"chr\"):\n",
    "        cands.append(chrom[3:])\n",
    "    else:\n",
    "        cands.append(\"chr\" + chrom)\n",
    "\n",
    "    # Map NC_0000XX.yy → 1..22/X/Y/MT\n",
    "    m = re.match(r\"NC_(\\d{6})\\.(\\d+)\", chrom)\n",
    "    if m:\n",
    "        num = int(m.group(1))\n",
    "        if 1 <= num <= 22:\n",
    "            cands += [str(num), f\"chr{num}\"]\n",
    "        elif num in NC_TO_ENSEMBL_SPECIAL:\n",
    "            val = NC_TO_ENSEMBL_SPECIAL[num]\n",
    "            cands += [val, f\"chr{val}\"]\n",
    "\n",
    "    # Support chrM/chrMT → MT\n",
    "    if chrom in (\"chrM\", \"chrMT\"):\n",
    "        cands += [\"MT\"]\n",
    "\n",
    "    # Deduplicate preserving order\n",
    "    out = []\n",
    "    for x in cands:\n",
    "        if x not in out:\n",
    "            out.append(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a91bb93e-3442-4459-9141-661b5fa621f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./clinvar_data/clinvar_STRICT_with_CADD.csv\n"
     ]
    }
   ],
   "source": [
    "# Save annotated dataset \n",
    "output = \"./clinvar_data/clinvar_STRICT_with_CADD.csv\"\n",
    "df.to_csv(output, index=False)\n",
    "print(\"Saved:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25b09e17-dec2-4f80-935f-1b3ddf6e39c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== First 5 ClinVar rows ===\n",
      "  CHROM     POS REF ALT  CLNSIG\n",
      "0     1  930165   G   A  Benign\n",
      "1     1  930204   G   A  Benign\n",
      "2     1  930285   G   A  Benign\n",
      "3     1  930314   C   T  Benign\n",
      "4     1  930325   C   T  Benign\n",
      "\n",
      "=== Matching CADD rows for first 5 ClinVar variants ===\n",
      "\n",
      "ClinVar #0: CHROM=1 POS=930165 REF=G ALT=A\n",
      "Matched CADD row: 1\t930165\tG\tA\t4.225333\t28.9\n",
      "\n",
      "ClinVar #1: CHROM=1 POS=930204 REF=G ALT=A\n",
      "Matched CADD row: 1\t930204\tG\tA\t2.879554\t23.2\n",
      "\n",
      "ClinVar #2: CHROM=1 POS=930285 REF=G ALT=A\n",
      "Matched CADD row: 1\t930285\tG\tA\t0.091394\t2.015\n",
      "\n",
      "ClinVar #3: CHROM=1 POS=930314 REF=C ALT=T\n",
      "Matched CADD row: 1\t930314\tC\tT\t2.481464\t22.4\n",
      "\n",
      "ClinVar #4: CHROM=1 POS=930325 REF=C ALT=T\n",
      "Matched CADD row: 1\t930325\tC\tT\t1.053778\t12.28\n",
      "\n",
      "=== First 5 CADD rows ===\n",
      "## CADD GRCh38-v1.6 (c) University of Washington, Hudson-Alpha Institute for Biotechnology and Berlin Institute of Health 2013-2020. All rights reserved.\n",
      "#Chrom\tPos\tRef\tAlt\tRawScore\tPHRED\n",
      "1\t10031\tT\tC\t0.756535\t8.973\n",
      "1\t10037\tT\tC\t0.748894\t8.902\n",
      "1\t10043\tT\tC\t0.748494\t8.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3995140/2302147126.py:7: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"./clinvar_data/clinvar_snv_pathogenic_benign_STRICT.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Optional\n",
    "# Before annotation, let's look at datasets.  \n",
    "import pandas as pd\n",
    "import pysam\n",
    "\n",
    "# ---- Load ClinVar ----\n",
    "df = pd.read_csv(\"./clinvar_data/clinvar_snv_pathogenic_benign_STRICT.csv\")\n",
    "\n",
    "print(\"=== First 5 ClinVar rows ===\")\n",
    "print(df[[\"CHROM\", \"POS\", \"REF\", \"ALT\", \"CLNSIG\"]].head())\n",
    "\n",
    "# ---------------------------\n",
    "# Try to find matching CADD rows \n",
    "# for the first 5 ClinVar variants\n",
    "# ---------------------------\n",
    "print(\"\\n=== Matching CADD rows for first 5 ClinVar variants ===\")\n",
    "\n",
    "def lookup_cadd(chrom, pos, ref, alt):\n",
    "    try:\n",
    "        for r in cadd_tabix.fetch(str(chrom), pos-1, pos):\n",
    "            fields = r.split(\"\\t\")\n",
    "            c_ref, c_alt = fields[2], fields[3]\n",
    "            if c_ref == ref and c_alt == alt:\n",
    "                return r\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "for idx in range(5):\n",
    "    row = df.iloc[idx]\n",
    "    chrom, pos, ref, alt = row[\"CHROM\"], int(row[\"POS\"]), row[\"REF\"], row[\"ALT\"]\n",
    "\n",
    "    print(f\"\\nClinVar #{idx}: CHROM={chrom} POS={pos} REF={ref} ALT={alt}\")\n",
    "    cadd_row = lookup_cadd(chrom, pos, ref, alt)\n",
    "\n",
    "    if cadd_row:\n",
    "        print(\"Matched CADD row:\", cadd_row)\n",
    "    else:\n",
    "        print(\"No matching CADD row found.\")\n",
    "\n",
    "# ---- Load CADD Tabix ----\n",
    "cadd_tabix = pysam.TabixFile(\"./cadd_data/gnomad_snv_cadd.tsv.gz\")\n",
    "\n",
    "print(\"\\n=== First 5 CADD rows ===\")\n",
    "import gzip\n",
    "\n",
    "with gzip.open(\"./cadd_data/gnomad_snv_cadd.tsv.gz\", \"rt\") as f:\n",
    "    for _ in range(5):\n",
    "        print(f.readline().strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99743139-89fa-4bd5-9e43-aae8be433dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating CADD: 100%|██████████| 262509/262509 [05:06<00:00, 856.43it/s] \n"
     ]
    }
   ],
   "source": [
    "# Annotate ClinVar dataset with CADD\n",
    "\n",
    "cadd_raw = []\n",
    "cadd_phred = []\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Annotating CADD\"):\n",
    "    raw, phred = get_cadd_score(\n",
    "        str(row[\"CHROM\"]),\n",
    "        int(row[\"POS\"]),\n",
    "        row[\"REF\"],\n",
    "        row[\"ALT\"],\n",
    "        cadd_tabix\n",
    "    )\n",
    "    cadd_raw.append(raw)\n",
    "    cadd_phred.append(phred)\n",
    "\n",
    "df[\"CADD_raw\"] = cadd_raw\n",
    "df[\"CADD_phred\"] = cadd_phred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b082a30e-1df1-4700-934b-03d2589a0bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262509, 7)\n",
      "After dropping missing values: (181036, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3995140/744477208.py:6: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"./clinvar_data/clinvar_STRICT_with_CADD.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train model \n",
    "\n",
    "# Load CADD-annotated dataset\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./clinvar_data/clinvar_STRICT_with_CADD.csv\")\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "# Clean dataset (drop missing CADD scores)\n",
    "df_clean = df.dropna(subset=[\"CADD_raw\", \"CADD_phred\"]).copy()\n",
    "print(\"After dropping missing values:\", df_clean.shape)\n",
    "\n",
    "# Encode labels \n",
    "#  Pathogenic is 1\n",
    "#  Benign is 0 \n",
    "\n",
    "df_clean[\"label\"] = (df_clean[\"CLNSIG\"] == \"Pathogenic\").astype(int)\n",
    "\n",
    "# Choose Features. Let's start with CADD_phred only\n",
    "# \"How good is CADD PHRED at distinguishing Pathogenic vs Benign?\"\n",
    "X = df_clean[[\"CADD_phred\"]].values\n",
    "y = df_clean[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f0bfe79-82bf-4bfd-b5f2-55a25babb19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression AUROC: 0.983308543201827\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     34171\n",
      "           1       0.90      0.73      0.81      2037\n",
      "\n",
      "    accuracy                           0.98     36208\n",
      "   macro avg       0.94      0.86      0.90     36208\n",
      "weighted avg       0.98      0.98      0.98     36208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Baseline \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "print(\"Logistic Regression AUROC:\", auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69cf3c8a-fca1-430a-8a1c-eab0259a2d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost AUROC: 0.9824731809221883\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     34171\n",
      "           1       0.89      0.74      0.81      2037\n",
      "\n",
      "    accuracy                           0.98     36208\n",
      "   macro avg       0.94      0.87      0.90     36208\n",
      "weighted avg       0.98      0.98      0.98     36208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Baseline \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"logloss\"\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_proba > 0.5).astype(int)\n",
    "\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "print(\"XGBoost AUROC:\", auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb40004-3e9f-4914-9d46-fdd848b80564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "nisgpuenv",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
